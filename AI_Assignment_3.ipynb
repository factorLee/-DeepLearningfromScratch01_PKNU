{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Assignment#3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/factorLee/DeepLearningfromScratch01_PKNU/blob/main/AI_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "six7aJxk6Im-"
      },
      "source": [
        "## 201730262 이상주 인공지능개론 과제#3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk7iHDmhzwO_",
        "outputId": "a1d78ac2-ce3f-4a17-be20-2af3ceddf6ad"
      },
      "source": [
        "!unzip ai.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open ai.zip, ai.zip.zip or ai.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inx_6FCM460S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19819416-c21e-48fc-e5be-dbcd714bb006"
      },
      "source": [
        "from tensorflow import keras\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ePFHgQPlGZq"
      },
      "source": [
        "## 데이터 차원 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWkJLTEHH6r7",
        "outputId": "f60333ca-29dd-49b2-a307-5f47e12ab5a8"
      },
      "source": [
        "print(x_train.shape) # 28X28 이미지 6만개\n",
        "print(x_train[0].shape) # 28X28 이미지 확인\n",
        "print(y_train.shape) # 패션물품 라벨 6만개\n",
        "print(y_train[0].shape) # scalar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(28, 28)\n",
            "(60000,)\n",
            "()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyME4zXH7-N",
        "outputId": "7a6d8938-3b28-48f8-e1ca-ddfa859be70a"
      },
      "source": [
        "# 테스트 데이터 확인\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvbbsm4Wzv8F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qovSihW3LRv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "6ebfb33e-cdad-4978-ad1a-cad875d2134f"
      },
      "source": [
        "from common.layers import *\n",
        "from common.gradient import *\n",
        "from collections import OrderedDict #순서를 기억하는 딕셔너리"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3d8051f87492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m \u001b[0;31m#순서를 기억하는 딕셔너리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkpN1Wm1lBXe"
      },
      "source": [
        "## Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xw0H5g33PPg"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, hidden01_size, hidden02_size, output_size,\n",
        "                 weight_init_std=0.01):\n",
        "        \n",
        "        # 패러미터 초기화\n",
        "        self.params={}\n",
        "        self.params['W1'] = weight_init_std*np.random.randn(input_size,hidden01_size)\n",
        "        self.params['b1'] = np.zeros(hidden01_size)\n",
        "        self.params['W2'] = weight_init_std*np.random.randn(hidden01_size,hidden02_size)\n",
        "        self.params['b2'] = np.zeros(hidden02_size)\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(hidden02_size, output_size)\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "        \n",
        "\n",
        "        # 계산할 layer를 추가\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'],self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2']= Affine(self.params['W2'], self.params['b2'])\n",
        "        self.layers['Relu2'] = Relu()\n",
        "        self.layers['Affine3']= Affine(self.params['W3'], self.params['b3'])\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "    # 신경망의 정방향 계산\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    # 주어진 x에 대하여 정답 y와 비교하여 Loss Function의 값을 계산\n",
        "    def loss(self,x,y):\n",
        "        y_pred = self.predict(x)\n",
        "        return self.lastLayer.forward(y_pred, y)\n",
        "\n",
        "    # 정확도 계산\n",
        "    def accuracy(self, x, y):\n",
        "        y_pred = self.predict(x)\n",
        "        y_pred = np.argmax(y_pred,axis=1)\n",
        "        if y.ndim != 1:\n",
        "            y = np.argmax(y,axis=1)\n",
        "        accuracy = np.sum(y_pred == y)/ float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    # 기울기 계산\n",
        "    def gradient(self, x, y):\n",
        "        self.loss(x,y)\n",
        "\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = self.layers['Affine1'].dW\n",
        "        grads['b1'] = self.layers['Affine1'].db\n",
        "        grads['W2'] = self.layers['Affine2'].dW\n",
        "        grads['b2'] = self.layers['Affine2'].db\n",
        "        grads['W3'] = self.layers['Affine3'].dW\n",
        "        grads['b3'] = self.layers['Affine3'].db\n",
        "        return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gw780Y3i2L7"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J_XWz6I3XTL"
      },
      "source": [
        "from mnist import load_mnist\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network =ThreeLayerNet(input_size=784, hidden01_size=50, hidden02_size=100, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "test_acc_list=[]\n",
        "\n",
        "iter_per_epoch = max(train_size/batch_size,1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    y_batch = y_train[batch_mask]\n",
        "\n",
        "    # 주어진 배치에서 기울기 계산\n",
        "    grad = network.gradient(x_batch,y_batch)\n",
        "\n",
        "    # 기울기에 따라 패러미터 갱신\n",
        "    for key in ['W1','b1','W2','b2','W3','b3']:\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    loss = network.loss(x_batch, y_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i%iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train,y_train)\n",
        "        test_acc = network.accuracy(x_test,y_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CcA2KwU3Ph3"
      },
      "source": [
        "------------------------------------------"
      ]
    }
  ]
}